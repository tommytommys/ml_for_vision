{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18b8e7e1",
   "metadata": {},
   "source": [
    "## Usa colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e08bcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installazione librerie principali\n",
    "!pip install -q ultralytics fiftyone opencv-python-headless\n",
    "!pip install -q matplotlib seaborn plotly scikit-learn pandas\n",
    "!pip install -q transformers datasets # Per il bonus HuggingFace\n",
    "\n",
    "print(\"‚úÖ Installazione completata!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import librerie\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torchvision\n",
    "from ultralytics import YOLO\n",
    "import ultralytics\n",
    "\n",
    "# FiftyOne per dataset\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "# Sklearn per metriche aggiuntive\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Configurazione visualizzazioni\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Verifica GPU\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "print(f\"üéÆ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"\\nüìä Ultralytics version: {ultralytics.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55332365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione globale del progetto\n",
    "CONFIG = {\n",
    "    'classes': ['Horse', 'Lizard', 'Mouse', 'Hamster', 'Mule'],\n",
    "    'num_classes': 5,\n",
    "    'dataset_name': 'animals-yolo',\n",
    "    'base_path': Path('/content/datasets'),\n",
    "    'min_images_per_class': 10,\n",
    "    'min_test_images': 100,\n",
    "    'train_ratio': 0.70,\n",
    "    'val_ratio': 0.15,\n",
    "    'test_ratio': 0.15,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Creazione struttura directory\n",
    "CONFIG['base_path'].mkdir(parents=True, exist_ok=True)\n",
    "print(\"‚úÖ Configurazione inizializzata\")\n",
    "print(f\"üìÅ Base path: {CONFIG['base_path']}\")\n",
    "print(f\"üéØ Classi: {', '.join(CONFIG['classes'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c110c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset da OpenImages v7\n",
    "# Scaricheremo solo le immagini che contengono almeno una delle nostre classi\n",
    "# OpenImages supporta sia detection che segmentation masks\n",
    "\n",
    "print(\"üöÄ Inizio download da OpenImages...\")\n",
    "print(f\"üì¶ Classi richieste: {CONFIG['classes']}\\n\")\n",
    "\n",
    "# Download del dataset con le classi specificate\n",
    "# max_samples=None per scaricare tutte le immagini disponibili (full version)\n",
    "# Questo pu√≤ richiedere diversi minuti\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"open-images-v7\",\n",
    "    split=\"train\",  # Useremo il train split di OpenImages, poi faremo il nostro split\n",
    "    label_types=[\"detections\", \"segmentations\"],  # Scarica sia bbox che maschere\n",
    "    classes=CONFIG['classes'],\n",
    "    max_samples=None,  # Full version: scarica tutto\n",
    "    dataset_name=\"openimages_animals\"\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset scaricato!\")\n",
    "print(f\"üìä Numero totale immagini: {len(dataset)}\")\n",
    "print(f\"üìÅ Dataset name: {dataset.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bf16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisi esplorativa del dataset\n",
    "print(\"üìä ANALISI ESPLORATIVA DEL DATASET\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Conteggio immagini per classe\n",
    "class_counts = {}\n",
    "for sample in dataset:\n",
    "    if sample.detections is not None:\n",
    "        for detection in sample.detections.detections:\n",
    "            label = detection.label\n",
    "            class_counts[label] = class_counts.get(label, 0) + 1\n",
    "\n",
    "print(\"\\nüéØ Numero di annotazioni (bounding boxes) per classe:\")\n",
    "for cls in CONFIG['classes']:\n",
    "    count = class_counts.get(cls, 0)\n",
    "    print(f\"   {cls:12s}: {count:4d} annotazioni\")\n",
    "\n",
    "print(f\"\\nüì∏ Totale immagini nel dataset: {len(dataset)}\")\n",
    "\n",
    "# Verifica disponibilit√† segmentation masks\n",
    "samples_with_segm = sum(1 for s in dataset if s.segmentations is not None and len(s.segmentations.detections) > 0)\n",
    "print(f\"üé® Immagini con segmentation masks: {samples_with_segm}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazione di alcune immagini di esempio\n",
    "# Questo ci aiuta a capire la qualit√† e variet√† del dataset\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def visualize_sample(sample, title=\"\"):\n",
    "    \"\"\"Visualizza un sample con bounding boxes\"\"\"\n",
    "    img = cv2.imread(sample.filepath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Disegna bounding boxes\n",
    "    if sample.detections:\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(CONFIG['classes'])))\n",
    "        class_colors = {cls: colors[i] for i, cls in enumerate(CONFIG['classes'])}\n",
    "        \n",
    "        for det in sample.detections.detections:\n",
    "            # Coordinate normalizzate -> pixel\n",
    "            x, y, w, h = det.bounding_box\n",
    "            x, y, w, h = x * img.shape[1], y * img.shape[0], w * img.shape[1], h * img.shape[0]\n",
    "            \n",
    "            color = class_colors.get(det.label, (1, 1, 1))\n",
    "            rect = mpatches.Rectangle(\n",
    "                (x, y), w, h,\n",
    "                linewidth=3,\n",
    "                edgecolor=color,\n",
    "                facecolor='none'\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            # Label\n",
    "            ax.text(\n",
    "                x, y - 10,\n",
    "                det.label,\n",
    "                bbox=dict(boxstyle='round', facecolor=color, alpha=0.7),\n",
    "                fontsize=10,\n",
    "                color='white',\n",
    "                fontweight='bold'\n",
    "            )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Mostra 3 esempi casuali per ogni classe\n",
    "print(\"üñºÔ∏è  VISUALIZZAZIONE ESEMPI DEL DATASET\\n\")\n",
    "\n",
    "for target_class in CONFIG['classes']:\n",
    "    # Trova un sample che contiene la classe target\n",
    "    for sample in dataset:\n",
    "        if sample.detections:\n",
    "            labels = [d.label for d in sample.detections.detections]\n",
    "            if target_class in labels:\n",
    "                visualize_sample(sample, f\"Esempio: {target_class}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687422ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split del dataset in Train/Val/Test\n",
    "import random\n",
    "\n",
    "print(\"‚úÇÔ∏è  SPLITTING DEL DATASET\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Imposta seed per riproducibilit√†\n",
    "random.seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "\n",
    "# Calcola le dimensioni degli split\n",
    "total_samples = len(dataset)\n",
    "train_size = int(total_samples * CONFIG['train_ratio'])\n",
    "val_size = int(total_samples * CONFIG['val_ratio'])\n",
    "test_size = total_samples - train_size - val_size\n",
    "\n",
    "print(f\"üìä Totale immagini: {total_samples}\")\n",
    "print(f\"   Train: {train_size} ({CONFIG['train_ratio']*100:.0f}%)\")\n",
    "print(f\"   Val:   {val_size} ({CONFIG['val_ratio']*100:.0f}%)\")\n",
    "print(f\"   Test:  {test_size} ({CONFIG['test_ratio']*100:.0f}%)\")\n",
    "\n",
    "# Crea gli split usando FiftyOne\n",
    "# Questo assicura che le immagini non si sovrappongano tra i set\n",
    "import fiftyone.utils.random as four\n",
    "\n",
    "four.random_split(\n",
    "    dataset,\n",
    "    {\n",
    "        \"train\": CONFIG['train_ratio'],\n",
    "        \"val\": CONFIG['val_ratio'],\n",
    "        \"test\": CONFIG['test_ratio']\n",
    "    },\n",
    "    seed=CONFIG['seed']\n",
    ")\n",
    "\n",
    "# Verifica gli split\n",
    "train_view = dataset.match_tags(\"train\")\n",
    "val_view = dataset.match_tags(\"val\")\n",
    "test_view = dataset.match_tags(\"test\")\n",
    "\n",
    "print(f\"\\n‚úÖ Split completato!\")\n",
    "print(f\"   Train samples: {len(train_view)}\")\n",
    "print(f\"   Val samples:   {len(val_view)}\")\n",
    "print(f\"   Test samples:  {len(test_view)}\")\n",
    "\n",
    "# Verifica vincoli sul test set\n",
    "print(f\"\\nüîç VERIFICA VINCOLI TEST SET:\")\n",
    "print(f\"   Minimo richiesto: {CONFIG['min_test_images']} immagini\")\n",
    "print(f\"   Ottenuto: {len(test_view)} immagini\")\n",
    "\n",
    "if len(test_view) >= CONFIG['min_test_images']:\n",
    "    print(\"   ‚úÖ Vincolo soddisfatto!\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è  ATTENZIONE: Test set troppo piccolo!\")\n",
    "\n",
    "# Verifica distribuzione classi nel test set\n",
    "test_class_counts = {}\n",
    "for sample in test_view:\n",
    "    if sample.detections:\n",
    "        for det in sample.detections.detections:\n",
    "            test_class_counts[det.label] = test_class_counts.get(det.label, 0) + 1\n",
    "\n",
    "print(f\"\\nüìä Distribuzione classi nel TEST SET:\")\n",
    "all_satisfied = True\n",
    "for cls in CONFIG['classes']:\n",
    "    count = test_class_counts.get(cls, 0)\n",
    "    status = \"‚úÖ\" if count >= CONFIG['min_images_per_class'] else \"‚ö†Ô∏è\"\n",
    "    print(f\"   {status} {cls:12s}: {count:3d} annotazioni\")\n",
    "    if count < CONFIG['min_images_per_class']:\n",
    "        all_satisfied = False\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export del dataset in formato YOLO\n",
    "print(\"üíæ EXPORT IN FORMATO YOLO\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Path di export\n",
    "export_dir = CONFIG['base_path'] / CONFIG['dataset_name']\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Directory di export: {export_dir}\\n\")\n",
    "\n",
    "# Check if segmentation data is available\n",
    "has_segmentation = False\n",
    "for sample in train_view.head(10):\n",
    "    if sample.segmentations and len(sample.segmentations.detections) > 0:\n",
    "        has_segmentation = True\n",
    "        break\n",
    "\n",
    "if has_segmentation:\n",
    "    print(\"‚úÖ Dataset ha segmentation masks - Export completo\\n\")\n",
    "    label_field = \"segmentations\"\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Dataset NON ha segmentation masks - Export solo detection\\n\")\n",
    "    print(\"   Nota: Training segmentation non sar√† possibile con questo dataset\")\n",
    "    print(\"   Soluzione: Scarica nuovamente con segmentation o usa solo detection\\n\")\n",
    "    label_field = \"detections\"\n",
    "\n",
    "# Export per ogni split\n",
    "for split_name, split_view in [(\"train\", train_view), (\"val\", val_view), (\"test\", test_view)]:\n",
    "    print(f\"üì¶ Esportando {split_name}...\")\n",
    "    \n",
    "    # FiftyOne pu√≤ esportare direttamente in formato YOLO\n",
    "    split_view.export(\n",
    "        export_dir=str(export_dir),\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        label_field=label_field,  # usa segmentations se disponibili\n",
    "        split=split_name,\n",
    "        classes=CONFIG['classes']\n",
    "    )\n",
    "    \n",
    "    print(f\"   ‚úÖ {split_name} esportato: {len(split_view)} immagini\")\n",
    "\n",
    "print(f\"\\n‚úÖ Export completato!\")\n",
    "print(f\"üìä Label field usato: {label_field}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione del file data.yaml per YOLO\n",
    "# Questo file √® essenziale per il training di YOLO\n",
    "\n",
    "yaml_path = export_dir / \"data.yaml\"\n",
    "\n",
    "yaml_content = f\"\"\"# Dataset configuration for YOLO\n",
    "# Auto-generated for Computer Vision Project\n",
    "\n",
    "path: {export_dir}  # dataset root dir\n",
    "train: images/train  # train images (relative to 'path')\n",
    "val: images/val      # val images (relative to 'path')\n",
    "test: images/test    # test images (relative to 'path')\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: Horse\n",
    "  1: Lizard\n",
    "  2: Mouse\n",
    "  3: Hamster\n",
    "  4: Mule\n",
    "\n",
    "nc: 5  # number of classes\n",
    "\"\"\"\n",
    "\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"üìÑ File data.yaml creato:\\n\")\n",
    "print(yaml_content)\n",
    "print(f\"üíæ Salvato in: {yaml_path}\")\n",
    "\n",
    "# Verifica struttura finale\n",
    "print(\"\\nüìÅ STRUTTURA DATASET FINALE:\")\n",
    "for root, dirs, files in os.walk(export_dir):\n",
    "    level = root.replace(str(export_dir), '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files[:3]:  # Mostra solo i primi 3 files per directory\n",
    "        print(f'{subindent}{file}')\n",
    "    if len(files) > 3:\n",
    "        print(f'{subindent}... and {len(files)-3} more files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585add31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import librerie\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from ultralytics import YOLO\n",
    "import ultralytics\n",
    "\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Versione PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA disponibile: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memoria GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "print(f\"Versione Ultralytics: {ultralytics.__version__}\")\n",
    "\n",
    "# Configurazione globale del progetto\n",
    "CONFIG = {\n",
    "    'classes': ['Horse', 'Lizard', 'Mouse', 'Hamster', 'Mule'],\n",
    "    'num_classes': 5,\n",
    "    'dataset_name': 'animals-yolo',\n",
    "    'base_path': Path('/content/datasets'),\n",
    "    'min_images_per_class': 10,\n",
    "    'min_test_images': 100,\n",
    "    'train_ratio': 0.70,\n",
    "    'val_ratio': 0.15,\n",
    "    'test_ratio': 0.15,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "CONFIG['base_path'].mkdir(parents=True, exist_ok=True)\n",
    "print(\"Configurazione inizializzata\")\n",
    "print(f\"Percorso base: {CONFIG['base_path']}\")\n",
    "print(f\"Classi: {', '.join(CONFIG['classes'])}\")\n",
    "\n",
    "# Download dataset da OpenImages v7\n",
    "print(\"\\nInizio download da OpenImages...\")\n",
    "print(f\"Classi richieste: {CONFIG['classes']}\\n\")\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"open-images-v7\",\n",
    "    split=\"train\",\n",
    "    label_types=[\"detections\", \"segmentations\"],\n",
    "    classes=CONFIG['classes'],\n",
    "    max_samples=None,\n",
    "    dataset_name=\"openimages_animals\"\n",
    ")\n",
    "\n",
    "print(f\"Dataset scaricato!\")\n",
    "print(f\"Numero totale immagini: {len(dataset)}\")\n",
    "print(f\"Nome dataset: {dataset.name}\")\n",
    "\n",
    "# Analisi esplorativa del dataset\n",
    "print(\"\\nANALISI ESPLORATIVA DEL DATASET\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class_counts = {}\n",
    "for sample in dataset:\n",
    "    if sample.detections is not None:\n",
    "        for detection in sample.detections.detections:\n",
    "            label = detection.label\n",
    "            class_counts[label] = class_counts.get(label, 0) + 1\n",
    "\n",
    "print(\"\\nAnnotazioni per classe:\")\n",
    "for cls in CONFIG['classes']:\n",
    "    count = class_counts.get(cls, 0)\n",
    "    print(f\"   {cls:12s}: {count:4d} annotazioni\")\n",
    "\n",
    "print(f\"\\nTotale immagini: {len(dataset)}\")\n",
    "\n",
    "samples_with_segm = sum(1 for s in dataset if s.segmentations is not None and len(s.segmentations.detections) > 0)\n",
    "print(f\"Immagini con maschere segmentazione: {samples_with_segm}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Funzione visualizzazione\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def visualizza_sample(sample, titolo=\"\"):\n",
    "    \"\"\"Visualizza un campione con bounding boxes\"\"\"\n",
    "    img = cv2.imread(sample.filepath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(titolo, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    if sample.detections:\n",
    "        colors = plt.cm.tab10(np.linspace(0, 1, len(CONFIG['classes'])))\n",
    "        class_colors = {cls: colors[i] for i, cls in enumerate(CONFIG['classes'])}\n",
    "        \n",
    "        for det in sample.detections.detections:\n",
    "            x, y, w, h = det.bounding_box\n",
    "            x, y, w, h = x * img.shape[1], y * img.shape[0], w * img.shape[1], h * img.shape[0]\n",
    "            \n",
    "            color = class_colors.get(det.label, (1, 1, 1))\n",
    "            rect = mpatches.Rectangle((x, y), w, h, linewidth=3, edgecolor=color, facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            ax.text(x, y - 10, det.label, bbox=dict(boxstyle='round', facecolor=color, alpha=0.7),\n",
    "                   fontsize=10, color='white', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Mostra esempi\n",
    "print(\"ESEMPI DI VISUALIZZAZIONE\\n\")\n",
    "\n",
    "for target_class in CONFIG['classes']:\n",
    "    for sample in dataset:\n",
    "        if sample.detections:\n",
    "            labels = [d.label for d in sample.detections.detections]\n",
    "            if target_class in labels:\n",
    "                visualizza_sample(sample, f\"Esempio: {target_class}\")\n",
    "                break\n",
    "\n",
    "# Split del dataset\n",
    "import random\n",
    "\n",
    "print(\"\\nDIVISIONE DEL DATASET\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "random.seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "\n",
    "total_samples = len(dataset)\n",
    "train_size = int(total_samples * CONFIG['train_ratio'])\n",
    "val_size = int(total_samples * CONFIG['val_ratio'])\n",
    "test_size = total_samples - train_size - val_size\n",
    "\n",
    "print(f\"Totale immagini: {total_samples}\")\n",
    "print(f\"   Addestramento: {train_size} ({CONFIG['train_ratio']*100:.0f}%)\")\n",
    "print(f\"   Validazione:   {val_size} ({CONFIG['val_ratio']*100:.0f}%)\")\n",
    "print(f\"   Test:          {test_size} ({CONFIG['test_ratio']*100:.0f}%)\")\n",
    "\n",
    "import fiftyone.utils.random as four\n",
    "\n",
    "four.random_split(\n",
    "    dataset,\n",
    "    {\n",
    "        \"train\": CONFIG['train_ratio'],\n",
    "        \"val\": CONFIG['val_ratio'],\n",
    "        \"test\": CONFIG['test_ratio']\n",
    "    },\n",
    "    seed=CONFIG['seed']\n",
    ")\n",
    "\n",
    "train_view = dataset.match_tags(\"train\")\n",
    "val_view = dataset.match_tags(\"val\")\n",
    "test_view = dataset.match_tags(\"test\")\n",
    "\n",
    "print(f\"\\nDivisione completata!\")\n",
    "print(f\"   Campioni addestramento: {len(train_view)}\")\n",
    "print(f\"   Campioni validazione:   {len(val_view)}\")\n",
    "print(f\"   Campioni test:          {len(test_view)}\")\n",
    "\n",
    "print(f\"\\nVERIFICA VINCOLI SET TEST:\")\n",
    "print(f\"   Minimo richiesto: {CONFIG['min_test_images']} immagini\")\n",
    "print(f\"   Ottenuto: {len(test_view)} immagini\")\n",
    "\n",
    "if len(test_view) >= CONFIG['min_test_images']:\n",
    "    print(\"   Vincolo soddisfatto!\")\n",
    "else:\n",
    "    print(f\"   ATTENZIONE: Set test troppo piccolo!\")\n",
    "\n",
    "test_class_counts = {}\n",
    "for sample in test_view:\n",
    "    if sample.detections:\n",
    "        for det in sample.detections.detections:\n",
    "            test_class_counts[det.label] = test_class_counts.get(det.label, 0) + 1\n",
    "\n",
    "print(f\"\\nDistribuzione classi nel SET TEST:\")\n",
    "all_satisfied = True\n",
    "for cls in CONFIG['classes']:\n",
    "    count = test_class_counts.get(cls, 0)\n",
    "    status = \"OK\" if count >= CONFIG['min_images_per_class'] else \"ATTENZIONE\"\n",
    "    print(f\"   [{status}] {cls:12s}: {count:3d} annotazioni\")\n",
    "    if count < CONFIG['min_images_per_class']:\n",
    "        all_satisfied = False\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Export in formato YOLO\n",
    "print(\"\\nEXPORT IN FORMATO YOLO\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "export_dir = CONFIG['base_path'] / CONFIG['dataset_name']\n",
    "export_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Directory export: {export_dir}\\n\")\n",
    "\n",
    "has_segmentation = False\n",
    "for sample in train_view.head(10):\n",
    "    if sample.segmentations and len(sample.segmentations.detections) > 0:\n",
    "        has_segmentation = True\n",
    "        break\n",
    "\n",
    "if has_segmentation:\n",
    "    print(\"Dataset contiene maschere segmentazione - Export completo\\n\")\n",
    "    label_field = \"segmentations\"\n",
    "else:\n",
    "    print(\"Dataset NON contiene maschere segmentazione - Solo detection\\n\")\n",
    "    print(\"Nota: Addestramento segmentazione non sar√† possibile\\n\")\n",
    "    label_field = \"detections\"\n",
    "\n",
    "for split_name, split_view in [(\"train\", train_view), (\"val\", val_view), (\"test\", test_view)]:\n",
    "    print(f\"Esportazione {split_name}...\")\n",
    "    \n",
    "    split_view.export(\n",
    "        export_dir=str(export_dir),\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        label_field=label_field,\n",
    "        split=split_name,\n",
    "        classes=CONFIG['classes']\n",
    "    )\n",
    "    \n",
    "    print(f\"   {split_name} esportato: {len(split_view)} immagini\")\n",
    "\n",
    "print(f\"\\nExport completato!\")\n",
    "print(f\"Campo etichette utilizzato: {label_field}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Creazione file data.yaml\n",
    "yaml_path = export_dir / \"data.yaml\"\n",
    "\n",
    "yaml_content = f\"\"\"path: {export_dir}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "names:\n",
    "  0: Horse\n",
    "  1: Lizard\n",
    "  2: Mouse\n",
    "  3: Hamster\n",
    "  4: Mule\n",
    "\n",
    "nc: 5\n",
    "\"\"\"\n",
    "\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"File data.yaml creato:\\n\")\n",
    "print(yaml_content)\n",
    "print(f\"Salvato in: {yaml_path}\")\n",
    "\n",
    "# Verifica struttura finale\n",
    "print(\"\\nSTRUTTURA DATASET FINALE:\")\n",
    "for root, dirs, files in os.walk(export_dir):\n",
    "    level = root.replace(str(export_dir), '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files[:3]:\n",
    "        print(f'{subindent}{file}')\n",
    "    if len(files) > 3:\n",
    "        print(f'{subindent}... e altri {len(files)-3} file')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
