{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b44066",
   "metadata": {},
   "source": [
    "##  Progetto di ML Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a92b5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifica ID classi trovate:\n",
      "‚úÖ horse = ID 39\n",
      "‚úÖ lizard = ID 48\n",
      "‚úÖ mouse = ID 52\n",
      "‚úÖ hamster = ID 34\n",
      "‚úÖ donkey = ID 21\n",
      "\n",
      "Analisi di 3779 file di annotazione in corso...\n",
      "------------------------------\n",
      "RISULTATI CONTEGGIO (TRAIN SET)\n",
      "------------------------------\n",
      "üì∑ Horse: 41 immagini\n",
      "üì∑ Lizard: 36 immagini\n",
      "üì∑ Mouse: 40 immagini\n",
      "üì∑ Hamster: 42 immagini\n",
      "üì∑ Donkey: 42 immagini\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from glob import glob\n",
    "\n",
    "# --- CONFIGURAZIONE ---\n",
    "# Inserisci qui il percorso della cartella principale del dataset (quella con il file data.yaml)\n",
    "dataset_path = r\"C:\\Users\\JadeOliverGuevarra\\Documents\\computer_vision\\project work\\Animal Detection.v1i.yolov11\"  # Es: \"C:/Users/Tu/Downloads/Animal-Detection-1\"\n",
    "\n",
    "# Le classi che vuoi controllare\n",
    "target_classes = ['horse', 'lizard', 'mouse', 'hamster', 'donkey']\n",
    "# ----------------------\n",
    "\n",
    "def count_yolo_classes():\n",
    "    # 1. Leggiamo il file data.yaml per capire quale ID numerico corrisponde a quale animale\n",
    "    yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
    "    \n",
    "    try:\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data_config = yaml.safe_load(f)\n",
    "            class_names = data_config['names'] # Lista dei nomi es: ['antelope', 'badger', ...]\n",
    "            \n",
    "            # Creiamo una mappa Inversa: Nome -> ID (es: {'horse': 15, 'mouse': 42})\n",
    "            # Gestiamo sia il caso in cui 'names' sia una lista che un dizionario\n",
    "            if isinstance(class_names, dict):\n",
    "                name_to_id = {v: k for k, v in class_names.items()}\n",
    "            else:\n",
    "                name_to_id = {name: i for i, name in enumerate(class_names)}\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Errore: Non trovo il file {yaml_path}. Controlla il percorso.\")\n",
    "        return\n",
    "\n",
    "    # Filtriamo solo gli ID degli animali che ti interessano\n",
    "    target_ids = {}\n",
    "    print(\"Verifica ID classi trovate:\")\n",
    "    for animal in target_classes:\n",
    "        if animal in name_to_id:\n",
    "            target_ids[name_to_id[animal]] = animal\n",
    "            print(f\"‚úÖ {animal} = ID {name_to_id[animal]}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {animal} non trovato nel file data.yaml!\")\n",
    "\n",
    "    if not target_ids:\n",
    "        print(\"Nessuna delle classi richieste √® stata trovata.\")\n",
    "        return\n",
    "\n",
    "    # 2. Contiamo le immagini nella cartella 'train/labels'\n",
    "    # In YOLO le annotazioni sono in file .txt dentro la cartella labels\n",
    "    labels_path = os.path.join(dataset_path, \"train\", \"labels\")\n",
    "    txt_files = glob(os.path.join(labels_path, \"*.txt\"))\n",
    "    \n",
    "    if not txt_files:\n",
    "        print(f\"Attenzione: Nessun file .txt trovato in {labels_path}\")\n",
    "        return\n",
    "\n",
    "    # Dizionario per contare: { 'horse': {set di file univoci}, ... }\n",
    "    counts = {animal: set() for animal in target_classes if animal in name_to_id}\n",
    "\n",
    "    print(f\"\\nAnalisi di {len(txt_files)} file di annotazione in corso...\")\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        with open(txt_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if not parts: continue\n",
    "            \n",
    "            # Il primo numero in una riga YOLO √® l'ID della classe\n",
    "            class_id = int(parts[0])\n",
    "            \n",
    "            # Se questo ID √® uno dei nostri target, segniamo il file\n",
    "            if class_id in target_ids:\n",
    "                animal_name = target_ids[class_id]\n",
    "                counts[animal_name].add(txt_file)\n",
    "\n",
    "    # 3. Risultati\n",
    "    print(\"-\" * 30)\n",
    "    print(\"RISULTATI CONTEGGIO (TRAIN SET)\")\n",
    "    print(\"-\" * 30)\n",
    "    for animal, files in counts.items():\n",
    "        print(f\"üì∑ {animal.capitalize()}: {len(files)} immagini\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    count_yolo_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24273428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from glob import glob\n",
    "\n",
    "# --- CONFIGURAZIONE ---\n",
    "# Inserisci qui il percorso della cartella principale del dataset (quella con il file data.yaml)\n",
    "dataset_path = r\"C:\\Users\\JadeOliverGuevarra\\Documents\\computer_vision\\project work\\Animal Detection.v1i.yolov11\"  # Es: \"C:/Users/Tu/Downloads/Animal-Detection-1\"\n",
    "\n",
    "# Le classi che vuoi controllare\n",
    "target_classes = ['horse', 'lizard', 'mouse', 'hamster', 'donkey']\n",
    "# ----------------------\n",
    "\n",
    "def count_yolo_classes():\n",
    "    # 1. Leggiamo il file data.yaml per capire quale ID numerico corrisponde a quale animale\n",
    "    yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
    "    \n",
    "    try:\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data_config = yaml.safe_load(f)\n",
    "            class_names = data_config['names'] # Lista dei nomi es: ['antelope', 'badger', ...]\n",
    "            \n",
    "            # Creiamo una mappa Inversa: Nome -> ID (es: {'horse': 15, 'mouse': 42})\n",
    "            # Gestiamo sia il caso in cui 'names' sia una lista che un dizionario\n",
    "            if isinstance(class_names, dict):\n",
    "                name_to_id = {v: k for k, v in class_names.items()}\n",
    "            else:\n",
    "                name_to_id = {name: i for i, name in enumerate(class_names)}\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Errore: Non trovo il file {yaml_path}. Controlla il percorso.\")\n",
    "        return\n",
    "\n",
    "    # Filtriamo solo gli ID degli animali che ti interessano\n",
    "    target_ids = {}\n",
    "    print(\"Verifica ID classi trovate:\")\n",
    "    for animal in target_classes:\n",
    "        if animal in name_to_id:\n",
    "            target_ids[name_to_id[animal]] = animal\n",
    "            print(f\"‚úÖ {animal} = ID {name_to_id[animal]}\")\n",
    "        else:\n",
    "            print(f\"‚ùå {animal} non trovato nel file data.yaml!\")\n",
    "\n",
    "    if not target_ids:\n",
    "        print(\"Nessuna delle classi richieste √® stata trovata.\")\n",
    "        return\n",
    "\n",
    "    # 2. Contiamo le immagini nella cartella 'train/labels'\n",
    "    # In YOLO le annotazioni sono in file .txt dentro la cartella labels\n",
    "    labels_path = os.path.join(dataset_path, \"train\", \"labels\")\n",
    "    txt_files = glob(os.path.join(labels_path, \"*.txt\"))\n",
    "    \n",
    "    if not txt_files:\n",
    "        print(f\"Attenzione: Nessun file .txt trovato in {labels_path}\")\n",
    "        return\n",
    "\n",
    "    # Dizionario per contare: { 'horse': {set di file univoci}, ... }\n",
    "    counts = {animal: set() for animal in target_classes if animal in name_to_id}\n",
    "\n",
    "    print(f\"\\nAnalisi di {len(txt_files)} file di annotazione in corso...\")\n",
    "\n",
    "    for txt_file in txt_files:\n",
    "        with open(txt_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if not parts: continue\n",
    "            \n",
    "            # Il primo numero in una riga YOLO √® l'ID della classe\n",
    "            class_id = int(parts[0])\n",
    "            \n",
    "            # Se questo ID √® uno dei nostri target, segniamo il file\n",
    "            if class_id in target_ids:\n",
    "                animal_name = target_ids[class_id]\n",
    "                counts[animal_name].add(txt_file)\n",
    "\n",
    "    # 3. Risultati\n",
    "    print(\"-\" * 30)\n",
    "    print(\"RISULTATI CONTEGGIO (TRAIN SET)\")\n",
    "    print(\"-\" * 30)\n",
    "    for animal, files in counts.items():\n",
    "        print(f\"üì∑ {animal.capitalize()}: {len(files)} immagini\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    count_yolo_classes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f25ef81",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ef8955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analisi in corso su: C:\\Users\\JadeOliverGuevarra\\Documents\\computer_vision\\project work\\Animal Detection.v1i.yolov11...\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "CLASSE          | TRAIN      | VALID      | TEST       | TOTALE    \n",
      "-----------------------------------------------------------------\n",
      "Horse           | 41         | 14         | 5          | 60        \n",
      "Lizard          | 36         | 9          | 13         | 58        \n",
      "Mouse           | 40         | 12         | 6          | 58        \n",
      "Hamster         | 42         | 16         | 2          | 60        \n",
      "Donkey          | 42         | 9          | 9          | 60        \n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from glob import glob\n",
    "\n",
    "# --- CONFIGURAZIONE ---\n",
    "# Inserisci il percorso della cartella principale (quella che contiene data.yaml)\n",
    "dataset_path = r\"C:\\Users\\JadeOliverGuevarra\\Documents\\computer_vision\\project work\\Animal Detection.v1i.yolov11\" \n",
    "\n",
    "# Le classi da cercare\n",
    "target_classes = ['horse', 'lizard', 'mouse', 'hamster', 'donkey']\n",
    "# ----------------------\n",
    "\n",
    "def count_all_splits():\n",
    "    # 1. Leggiamo il data.yaml per la mappatura ID -> Nome\n",
    "    yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
    "    \n",
    "    try:\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data_config = yaml.safe_load(f)\n",
    "            class_names = data_config['names']\n",
    "            \n",
    "            # Mappa Nome -> ID\n",
    "            if isinstance(class_names, dict):\n",
    "                name_to_id = {v: k for k, v in class_names.items()}\n",
    "            else:\n",
    "                name_to_id = {name: i for i, name in enumerate(class_names)}\n",
    "                \n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Errore: File data.yaml non trovato in {dataset_path}\")\n",
    "        return\n",
    "\n",
    "    # Filtriamo solo gli ID richiesti\n",
    "    target_ids = {}\n",
    "    for animal in target_classes:\n",
    "        if animal in name_to_id:\n",
    "            target_ids[name_to_id[animal]] = animal\n",
    "    \n",
    "    if not target_ids:\n",
    "        print(\"‚ùå Nessuna classe trovata nel file yaml.\")\n",
    "        return\n",
    "\n",
    "    # 2. Prepariamo la struttura per i risultati\n",
    "    # Struttura: {'horse': {'train': 0, 'valid': 0, 'test': 0}, ...}\n",
    "    splits = ['train', 'valid', 'test']\n",
    "    results = {animal: {s: 0 for s in splits} for animal in target_classes}\n",
    "\n",
    "    # 3. Iteriamo su ogni cartella (train, valid, test)\n",
    "    print(f\"Analisi in corso su: {dataset_path}...\\n\")\n",
    "    \n",
    "    for split in splits:\n",
    "        labels_path = os.path.join(dataset_path, split, \"labels\")\n",
    "        txt_files = glob(os.path.join(labels_path, \"*.txt\"))\n",
    "        \n",
    "        if not txt_files:\n",
    "            print(f\"‚ö†Ô∏è  Attenzione: Cartella '{split}' vuota o non trovata.\")\n",
    "            continue\n",
    "\n",
    "        for txt_file in txt_files:\n",
    "            with open(txt_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            # Usiamo un set per questa singola immagine per non contare due volte \n",
    "            # lo stesso animale nella stessa foto (es. 2 cavalli in 1 foto = 1 foto di cavalli)\n",
    "            classes_in_image = set()\n",
    "            \n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if parts:\n",
    "                    classes_in_image.add(int(parts[0]))\n",
    "            \n",
    "            # Aggiorniamo i contatori globali\n",
    "            for cls_id in classes_in_image:\n",
    "                if cls_id in target_ids:\n",
    "                    animal_name = target_ids[cls_id]\n",
    "                    results[animal_name][split] += 1\n",
    "\n",
    "    # 4. Stampa Risultati in Tabella\n",
    "    print(\"-\" * 65)\n",
    "    print(f\"{'CLASSE':<15} | {'TRAIN':<10} | {'VALID':<10} | {'TEST':<10} | {'TOTALE':<10}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for animal in target_classes:\n",
    "        if animal in results:\n",
    "            train_c = results[animal]['train']\n",
    "            valid_c = results[animal]['valid']\n",
    "            test_c  = results[animal]['test']\n",
    "            total_c = train_c + valid_c + test_c\n",
    "            \n",
    "            print(f\"{animal.capitalize():<15} | {train_c:<10} | {valid_c:<10} | {test_c:<10} | {total_c:<10}\")\n",
    "        else:\n",
    "             print(f\"{animal.capitalize():<15} | NON TROVATA NEL DATASET\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    count_all_splits()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a27a8fc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Compensiamo le mancanze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ba1371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio riorganizzazione dataset in: C:\\Users\\JadeOliverGuevarra\\Documents\\computer_vision\\project work\\Animal Detection.v1i.yolov11\n",
      "Trovate 5399 coppie totali di immagini/annotazioni.\n",
      "Nuova distribuzione prevista -> Train: 5264, Valid: 30, Test: 105\n",
      "‚úÖ Riorganizzazione completata!\n",
      "Ora esegui di nuovo lo script di conteggio per verificare.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURAZIONE ---\n",
    "# Il percorso della cartella principale del dataset\n",
    "dataset_path = r\"C:\\Users\\JadeOliverGuevarra\\Documents\\computer_vision\\project work\\Animal Detection.v1i.yolov11\"\n",
    "\n",
    "# Quante immagini vuoi ESATTAMENTE nel test set? (Mettiamo 105 per stare sicuri sopra i 100)\n",
    "DESIRED_TEST_COUNT = 105\n",
    "# Quante nel validation?\n",
    "DESIRED_VALID_COUNT = 30\n",
    "# Il resto andr√† tutto nel TRAIN\n",
    "# ----------------------\n",
    "\n",
    "def split_dataset():\n",
    "    print(f\"Inizio riorganizzazione dataset in: {dataset_path}\")\n",
    "    \n",
    "    # 1. Raccogliamo tutte le coppie (immagine + label) da tutte le sottocartelle\n",
    "    all_pairs = []\n",
    "    extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
    "    \n",
    "    # Cerchiamo in train, valid, test\n",
    "    for split in ['train', 'valid', 'test', 'val']:\n",
    "        img_path = os.path.join(dataset_path, split, 'images')\n",
    "        lbl_path = os.path.join(dataset_path, split, 'labels')\n",
    "        \n",
    "        if not os.path.exists(img_path): continue\n",
    "        \n",
    "        # Trova tutte le immagini\n",
    "        images = []\n",
    "        for ext in extensions:\n",
    "            images.extend(glob(os.path.join(img_path, ext)))\n",
    "            \n",
    "        for img_file in images:\n",
    "            # Trova il file txt corrispondente\n",
    "            basename = os.path.splitext(os.path.basename(img_file))[0]\n",
    "            txt_file = os.path.join(lbl_path, basename + '.txt')\n",
    "            \n",
    "            if os.path.exists(txt_file):\n",
    "                all_pairs.append({'img': img_file, 'txt': txt_file, 'base': basename})\n",
    "    \n",
    "    total_files = len(all_pairs)\n",
    "    print(f\"Trovate {total_files} coppie totali di immagini/annotazioni.\")\n",
    "    \n",
    "    if total_files < DESIRED_TEST_COUNT:\n",
    "        print(\"ERRORE: Non hai abbastanza immagini totali per soddisfare la richiesta del test set!\")\n",
    "        return\n",
    "\n",
    "    # 2. Mescoliamo casualmente (SHUFFLE)\n",
    "    random.seed(42) # Usiamo un seed fisso per riproducibilit√†, se vuoi variare togli questa riga\n",
    "    random.shuffle(all_pairs)\n",
    "    \n",
    "    # 3. Definiamo i tagli\n",
    "    test_set = all_pairs[:DESIRED_TEST_COUNT]\n",
    "    valid_set = all_pairs[DESIRED_TEST_COUNT : DESIRED_TEST_COUNT + DESIRED_VALID_COUNT]\n",
    "    train_set = all_pairs[DESIRED_TEST_COUNT + DESIRED_VALID_COUNT:]\n",
    "    \n",
    "    print(f\"Nuova distribuzione prevista -> Train: {len(train_set)}, Valid: {len(valid_set)}, Test: {len(test_set)}\")\n",
    "\n",
    "    # 4. Spostiamo i file\n",
    "    # Creiamo una cartella temporanea per evitare conflitti se spostiamo file su se stessi\n",
    "    # Ma dato che la struttura YOLO √® fissa, possiamo sovrascrivere se stiamo attenti.\n",
    "    # Per sicurezza, svuotiamo le cartelle di destinazione logica o le ricreiamo?\n",
    "    # Approccio sicuro: Spostiamo tutto dove deve andare.\n",
    "    \n",
    "    splits_map = {\n",
    "        'train': train_set,\n",
    "        'valid': valid_set,\n",
    "        'test': test_set\n",
    "    }\n",
    "    \n",
    "    for split_name, pairs in splits_map.items():\n",
    "        # Percorsi destinazione\n",
    "        dest_img_dir = os.path.join(dataset_path, split_name, 'images')\n",
    "        dest_lbl_dir = os.path.join(dataset_path, split_name, 'labels')\n",
    "        \n",
    "        # Assicuriamoci che esistano\n",
    "        os.makedirs(dest_img_dir, exist_ok=True)\n",
    "        os.makedirs(dest_lbl_dir, exist_ok=True)\n",
    "        \n",
    "        for pair in pairs:\n",
    "            # Nuovi percorsi\n",
    "            new_img_path = os.path.join(dest_img_dir, os.path.basename(pair['img']))\n",
    "            new_txt_path = os.path.join(dest_lbl_dir, os.path.basename(pair['txt']))\n",
    "            \n",
    "            # Spostiamo (usiamo shutil.move che gestisce anche se il file √® gi√† l√¨ vicino)\n",
    "            # Controllo per non sovrascrivere se per caso sorgente == destinazione\n",
    "            if pair['img'] != new_img_path:\n",
    "                shutil.move(pair['img'], new_img_path)\n",
    "            if pair['txt'] != new_txt_path:\n",
    "                shutil.move(pair['txt'], new_txt_path)\n",
    "                \n",
    "    print(\"‚úÖ Riorganizzazione completata!\")\n",
    "    print(\"Ora esegui di nuovo lo script di conteggio per verificare.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e4ca18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifica requisiti in corso su: C:\\Users\\JadeOliverGuevarra\\Documents\\computer_vision\\project work\\Animal Detection.v1i.yolov11...\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "CLASSE          | TRAIN      | VALID      | TEST       | TOTALE    \n",
      "-----------------------------------------------------------------\n",
      "Horse           | 56         | 1          | 3          | 60        \n",
      "Lizard          | 57         | 1          | 0          | 58        \n",
      "Mouse           | 56         | 1          | 1          | 58        \n",
      "Hamster         | 58         | 1          | 1          | 60        \n",
      "Donkey          | 60         | 0          | 0          | 60        \n",
      "-----------------------------------------------------------------\n",
      "TOTALE FOTO NEL TEST SET: 105\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "ESITO VERIFICA:\n",
      "‚úÖ Requisito 1: Almeno 100 immagini nel Test Set -> SODDISFATTO\n",
      "‚ùå Requisito 2: Almeno 10 immagini per classe -> NON SODDISFATTO (Minimo trovato: 0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from glob import glob\n",
    "\n",
    "# --- AGGIORNA SOLO QUESTO PERCORSO ---\n",
    "dataset_path = r\"C:\\Users\\JadeOliverGuevarra\\Documents\\computer_vision\\project work\\Animal Detection.v1i.yolov11\"\n",
    "# -------------------------------------\n",
    "\n",
    "target_classes = ['horse', 'lizard', 'mouse', 'hamster', 'donkey']\n",
    "\n",
    "def verify_dataset():\n",
    "    print(f\"Verifica requisiti in corso su: {dataset_path}...\\n\")\n",
    "    \n",
    "    # 1. Mappatura Nomi -> ID\n",
    "    yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
    "    try:\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "            names = data['names']\n",
    "            # Gestione lista o dizionario\n",
    "            if isinstance(names, dict):\n",
    "                name_to_id = {v: k for k, v in names.items()}\n",
    "            else:\n",
    "                name_to_id = {n: i for i, n in enumerate(names)}\n",
    "    except Exception as e:\n",
    "        print(f\"Errore lettura YAML: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Conteggio\n",
    "    splits = ['train', 'valid', 'test']\n",
    "    results = {animal: {s: 0 for s in splits} for animal in target_classes}\n",
    "    total_test_images = 0\n",
    "\n",
    "    for split in splits:\n",
    "        txt_files = glob(os.path.join(dataset_path, split, \"labels\", \"*.txt\"))\n",
    "        \n",
    "        # Conteggio per il totale del Test set\n",
    "        if split == 'test':\n",
    "            total_test_images = len(txt_files)\n",
    "\n",
    "        for txt_file in txt_files:\n",
    "            with open(txt_file, 'r') as f:\n",
    "                content = f.read()\n",
    "                \n",
    "            # Identifichiamo quali animali sono presenti in questo file\n",
    "            found_ids = set()\n",
    "            for line in content.splitlines():\n",
    "                if line.strip():\n",
    "                    class_id = int(line.split()[0])\n",
    "                    found_ids.add(class_id)\n",
    "            \n",
    "            # Aggiorniamo la tabella\n",
    "            for animal in target_classes:\n",
    "                if animal in name_to_id:\n",
    "                    aid = name_to_id[animal]\n",
    "                    if aid in found_ids:\n",
    "                        results[animal][split] += 1\n",
    "\n",
    "    # 3. Stampa Tabella e Verdetto\n",
    "    print(\"-\" * 65)\n",
    "    print(f\"{'CLASSE':<15} | {'TRAIN':<10} | {'VALID':<10} | {'TEST':<10} | {'TOTALE':<10}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    min_class_count = 9999\n",
    "    \n",
    "    for animal in target_classes:\n",
    "        t = results[animal]['test']\n",
    "        print(f\"{animal.capitalize():<15} | {results[animal]['train']:<10} | {results[animal]['valid']:<10} | {t:<10} | {sum(results[animal].values()):<10}\")\n",
    "        if t < min_class_count:\n",
    "            min_class_count = t\n",
    "\n",
    "    print(\"-\" * 65)\n",
    "    print(f\"TOTALE FOTO NEL TEST SET: {total_test_images}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    # 4. Controllo automatico dei requisiti\n",
    "    print(\"\\nESITO VERIFICA:\")\n",
    "    \n",
    "    check_1 = total_test_images >= 100\n",
    "    check_2 = min_class_count >= 10\n",
    "    \n",
    "    if check_1:\n",
    "        print(\"‚úÖ Requisito 1: Almeno 100 immagini nel Test Set -> SODDISFATTO\")\n",
    "    else:\n",
    "        print(f\"‚ùå Requisito 1: Almeno 100 immagini nel Test Set -> NON SODDISFATTO ({total_test_images}/100)\")\n",
    "        \n",
    "    if check_2:\n",
    "        print(\"‚úÖ Requisito 2: Almeno 10 immagini per classe nel Test -> SODDISFATTO\")\n",
    "    else:\n",
    "        print(f\"‚ùå Requisito 2: Almeno 10 immagini per classe -> NON SODDISFATTO (Minimo trovato: {min_class_count})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    verify_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c426d19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "393cf45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Avvio bilanciamento INTELLIGENTE su: C:\\Users\\JadeOliverGuevarra\\Documents\\computer_vision\\project work\\Animal Detection.v1i.yolov11\n",
      "üìã ID Target trovati: {39: 'horse', 48: 'lizard', 52: 'mouse', 34: 'hamster', 21: 'donkey'}\n",
      "üì¶ Raccolta di tutti i file...\n",
      "üìä Totale file trovati: 5399\n",
      "üéØ Fase 1: Assegnazione prioritaria Test Set...\n",
      "   -> Assegnati 12 file per la classe 'horse' al Test.\n",
      "   -> Assegnati 12 file per la classe 'lizard' al Test.\n",
      "   -> Assegnati 12 file per la classe 'mouse' al Test.\n",
      "   -> Assegnati 12 file per la classe 'hamster' al Test.\n",
      "   -> Assegnati 12 file per la classe 'donkey' al Test.\n",
      "‚öñÔ∏è Fase 2: Riempimento Valid Set...\n",
      "üì• Fase 3: Aggiunta di 45 file random al Test per raggiungere quota 105...\n",
      "\n",
      "üìù Riassunto pianificazione:\n",
      "   TRAIN: 5264\n",
      "   VALID: 30\n",
      "   TEST:  105 (Target minimo 10/classe garantito)\n",
      "\n",
      "üöÄ Esecuzione spostamenti fisici...\n",
      "‚úÖ Ribilanciamento completato con successo.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import yaml\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- CONFIGURAZIONE ---\n",
    "dataset_path = r\"C:\\Users\\JadeOliverGuevarra\\Documents\\computer_vision\\project work\\Animal Detection.v1i.yolov11\"\n",
    "target_classes_names = ['horse', 'lizard', 'mouse', 'hamster', 'donkey']\n",
    "REQUIRED_TEST_PER_CLASS = 12  # Ne mettiamo 12 per essere sicuri di superare i 10\n",
    "TOTAL_TEST_SIZE = 105         # Obiettivo totale immagini test\n",
    "# ----------------------\n",
    "\n",
    "def stratified_resplit():\n",
    "    print(f\"üîÑ Avvio bilanciamento INTELLIGENTE su: {dataset_path}\")\n",
    "\n",
    "    # 1. Mappatura Classi dal YAML\n",
    "    yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
    "    try:\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data_cfg = yaml.safe_load(f)\n",
    "            names = data_cfg['names']\n",
    "            if isinstance(names, dict):\n",
    "                name_to_id = {v: k for k, v in names.items()}\n",
    "            else:\n",
    "                name_to_id = {n: i for i, n in enumerate(names)}\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Errore YAML: {e}\")\n",
    "        return\n",
    "\n",
    "    target_ids = {name_to_id[n]: n for n in target_classes_names if n in name_to_id}\n",
    "    print(f\"üìã ID Target trovati: {target_ids}\")\n",
    "\n",
    "    # 2. Raccogliamo TUTTI i file in un unico pool\n",
    "    print(\"üì¶ Raccolta di tutti i file...\")\n",
    "    all_files = [] # Lista di tuple (img_path, txt_path, elenco_classi_nel_file)\n",
    "    \n",
    "    # Cerchiamo in tutte le cartelle possibili\n",
    "    for split in ['train', 'valid', 'test', 'val']:\n",
    "        lbl_dir = os.path.join(dataset_path, split, 'labels')\n",
    "        img_dir = os.path.join(dataset_path, split, 'images')\n",
    "        \n",
    "        txts = glob(os.path.join(lbl_dir, \"*.txt\"))\n",
    "        for txt in txts:\n",
    "            basename = os.path.basename(txt)\n",
    "            img_name = os.path.splitext(basename)[0] + \".jpg\" # Assumiamo jpg, poi controlliamo\n",
    "            # Cerchiamo l'immagine corrispondente (gestione estensioni)\n",
    "            found_img = None\n",
    "            for ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n",
    "                probe = os.path.join(img_dir, os.path.splitext(basename)[0] + ext)\n",
    "                if os.path.exists(probe):\n",
    "                    found_img = probe\n",
    "                    break\n",
    "            \n",
    "            if found_img:\n",
    "                # Leggiamo quali classi ci sono dentro\n",
    "                with open(txt, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                classes_in_file = set()\n",
    "                for line in lines:\n",
    "                    if line.strip():\n",
    "                        classes_in_file.add(int(line.split()[0]))\n",
    "                \n",
    "                all_files.append({\n",
    "                    'img': found_img,\n",
    "                    'txt': txt,\n",
    "                    'classes': classes_in_file,\n",
    "                    'id': basename\n",
    "                })\n",
    "\n",
    "    print(f\"üìä Totale file trovati: {len(all_files)}\")\n",
    "\n",
    "    # 3. Allocazione Strategica\n",
    "    test_set = []\n",
    "    valid_set = []\n",
    "    train_set = []\n",
    "    \n",
    "    assigned_ids = set() # Per non duplicare file\n",
    "\n",
    "    # A. PRIMA PASSA: Soddisfare il requisito \"Minimo 10 per classe nel Test\"\n",
    "    print(\"üéØ Fase 1: Assegnazione prioritaria Test Set...\")\n",
    "    for tid, tname in target_ids.items():\n",
    "        count = 0\n",
    "        # Mischiamo per variare\n",
    "        random.shuffle(all_files)\n",
    "        \n",
    "        for file in all_files:\n",
    "            if file['id'] in assigned_ids: continue\n",
    "            \n",
    "            if tid in file['classes']:\n",
    "                test_set.append(file)\n",
    "                assigned_ids.add(file['id'])\n",
    "                count += 1\n",
    "                if count >= REQUIRED_TEST_PER_CLASS:\n",
    "                    break\n",
    "        print(f\"   -> Assegnati {count} file per la classe '{tname}' al Test.\")\n",
    "\n",
    "    # B. SECONDA PASSA: Valid Set (ne mettiamo un po' a caso, es. 30 totali)\n",
    "    print(\"‚öñÔ∏è Fase 2: Riempimento Valid Set...\")\n",
    "    remaining = [f for f in all_files if f['id'] not in assigned_ids]\n",
    "    random.shuffle(remaining)\n",
    "    \n",
    "    # Prendiamo 30 file per valid\n",
    "    for _ in range(30):\n",
    "        if not remaining: break\n",
    "        file = remaining.pop()\n",
    "        valid_set.append(file)\n",
    "        assigned_ids.add(file['id'])\n",
    "\n",
    "    # C. TERZA PASSA: Riempire il Test fino a 105 totali\n",
    "    curr_test_len = len(test_set)\n",
    "    needed = TOTAL_TEST_SIZE - curr_test_len\n",
    "    if needed > 0:\n",
    "        print(f\"üì• Fase 3: Aggiunta di {needed} file random al Test per raggiungere quota {TOTAL_TEST_SIZE}...\")\n",
    "        # Cerchiamo di prendere file che HANNO animali target se possibile, altrimenti qualsiasi cosa\n",
    "        remaining = [f for f in all_files if f['id'] not in assigned_ids]\n",
    "        \n",
    "        # Ordiniamo: prima quelli che hanno target classes, poi gli altri\n",
    "        def has_target(f):\n",
    "            return any(c in target_ids for c in f['classes'])\n",
    "        \n",
    "        remaining.sort(key=has_target, reverse=True)\n",
    "        \n",
    "        for _ in range(needed):\n",
    "            if not remaining: break\n",
    "            file = remaining.pop(0) # Prendi il primo (il pi√π rilevante)\n",
    "            test_set.append(file)\n",
    "            assigned_ids.add(file['id'])\n",
    "\n",
    "    # D. QUARTA PASSA: Tutto il resto in Train\n",
    "    train_set = [f for f in all_files if f['id'] not in assigned_ids]\n",
    "\n",
    "    print(f\"\\nüìù Riassunto pianificazione:\")\n",
    "    print(f\"   TRAIN: {len(train_set)}\")\n",
    "    print(f\"   VALID: {len(valid_set)}\")\n",
    "    print(f\"   TEST:  {len(test_set)} (Target minimo 10/classe garantito)\")\n",
    "\n",
    "    # 4. Esecuzione Spostamenti\n",
    "    print(\"\\nüöÄ Esecuzione spostamenti fisici...\")\n",
    "    \n",
    "    # Creiamo cartelle se non esistono\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        os.makedirs(os.path.join(dataset_path, split, 'images'), exist_ok=True)\n",
    "        os.makedirs(os.path.join(dataset_path, split, 'labels'), exist_ok=True)\n",
    "\n",
    "    splits_data = {'train': train_set, 'valid': valid_set, 'test': test_set}\n",
    "\n",
    "    for split_name, files in splits_data.items():\n",
    "        dest_img_dir = os.path.join(dataset_path, split_name, 'images')\n",
    "        dest_lbl_dir = os.path.join(dataset_path, split_name, 'labels')\n",
    "        \n",
    "        for f in files:\n",
    "            # Sposta Immagine\n",
    "            shutil.move(f['img'], os.path.join(dest_img_dir, os.path.basename(f['img'])))\n",
    "            # Sposta Label\n",
    "            shutil.move(f['txt'], os.path.join(dest_lbl_dir, os.path.basename(f['txt'])))\n",
    "\n",
    "    print(\"‚úÖ Ribilanciamento completato con successo.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stratified_resplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf01341d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifica requisiti in corso su: C:\\Users\\JadeOliverGuevarra\\Documents\\computer_vision\\project work\\Animal Detection.v1i.yolov11...\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "CLASSE          | TRAIN      | VALID      | TEST       | TOTALE    \n",
      "-----------------------------------------------------------------\n",
      "Horse           | 42         | 0          | 18         | 60        \n",
      "Lizard          | 31         | 2          | 25         | 58        \n",
      "Mouse           | 34         | 0          | 24         | 58        \n",
      "Hamster         | 34         | 1          | 25         | 60        \n",
      "Donkey          | 46         | 1          | 13         | 60        \n",
      "-----------------------------------------------------------------\n",
      "TOTALE FOTO NEL TEST SET: 105\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "ESITO VERIFICA:\n",
      "‚úÖ Requisito 1: Almeno 100 immagini nel Test Set -> SODDISFATTO\n",
      "‚úÖ Requisito 2: Almeno 10 immagini per classe nel Test -> SODDISFATTO\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from glob import glob\n",
    "\n",
    "# --- AGGIORNA SOLO QUESTO PERCORSO ---\n",
    "dataset_path = r\"C:\\Users\\JadeOliverGuevarra\\Documents\\computer_vision\\project work\\Animal Detection.v1i.yolov11\"\n",
    "# -------------------------------------\n",
    "\n",
    "target_classes = ['horse', 'lizard', 'mouse', 'hamster', 'donkey']\n",
    "\n",
    "def verify_dataset():\n",
    "    print(f\"Verifica requisiti in corso su: {dataset_path}...\\n\")\n",
    "    \n",
    "    # 1. Mappatura Nomi -> ID\n",
    "    yaml_path = os.path.join(dataset_path, \"data.yaml\")\n",
    "    try:\n",
    "        with open(yaml_path, 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "            names = data['names']\n",
    "            # Gestione lista o dizionario\n",
    "            if isinstance(names, dict):\n",
    "                name_to_id = {v: k for k, v in names.items()}\n",
    "            else:\n",
    "                name_to_id = {n: i for i, n in enumerate(names)}\n",
    "    except Exception as e:\n",
    "        print(f\"Errore lettura YAML: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Conteggio\n",
    "    splits = ['train', 'valid', 'test']\n",
    "    results = {animal: {s: 0 for s in splits} for animal in target_classes}\n",
    "    total_test_images = 0\n",
    "\n",
    "    for split in splits:\n",
    "        txt_files = glob(os.path.join(dataset_path, split, \"labels\", \"*.txt\"))\n",
    "        \n",
    "        # Conteggio per il totale del Test set\n",
    "        if split == 'test':\n",
    "            total_test_images = len(txt_files)\n",
    "\n",
    "        for txt_file in txt_files:\n",
    "            with open(txt_file, 'r') as f:\n",
    "                content = f.read()\n",
    "                \n",
    "            # Identifichiamo quali animali sono presenti in questo file\n",
    "            found_ids = set()\n",
    "            for line in content.splitlines():\n",
    "                if line.strip():\n",
    "                    class_id = int(line.split()[0])\n",
    "                    found_ids.add(class_id)\n",
    "            \n",
    "            # Aggiorniamo la tabella\n",
    "            for animal in target_classes:\n",
    "                if animal in name_to_id:\n",
    "                    aid = name_to_id[animal]\n",
    "                    if aid in found_ids:\n",
    "                        results[animal][split] += 1\n",
    "\n",
    "    # 3. Stampa Tabella e Verdetto\n",
    "    print(\"-\" * 65)\n",
    "    print(f\"{'CLASSE':<15} | {'TRAIN':<10} | {'VALID':<10} | {'TEST':<10} | {'TOTALE':<10}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    min_class_count = 9999\n",
    "    \n",
    "    for animal in target_classes:\n",
    "        t = results[animal]['test']\n",
    "        print(f\"{animal.capitalize():<15} | {results[animal]['train']:<10} | {results[animal]['valid']:<10} | {t:<10} | {sum(results[animal].values()):<10}\")\n",
    "        if t < min_class_count:\n",
    "            min_class_count = t\n",
    "\n",
    "    print(\"-\" * 65)\n",
    "    print(f\"TOTALE FOTO NEL TEST SET: {total_test_images}\")\n",
    "    print(\"-\" * 65)\n",
    "\n",
    "    # 4. Controllo automatico dei requisiti\n",
    "    print(\"\\nESITO VERIFICA:\")\n",
    "    \n",
    "    check_1 = total_test_images >= 100\n",
    "    check_2 = min_class_count >= 10\n",
    "    \n",
    "    if check_1:\n",
    "        print(\"‚úÖ Requisito 1: Almeno 100 immagini nel Test Set -> SODDISFATTO\")\n",
    "    else:\n",
    "        print(f\"‚ùå Requisito 1: Almeno 100 immagini nel Test Set -> NON SODDISFATTO ({total_test_images}/100)\")\n",
    "        \n",
    "    if check_2:\n",
    "        print(\"‚úÖ Requisito 2: Almeno 10 immagini per classe nel Test -> SODDISFATTO\")\n",
    "    else:\n",
    "        print(f\"‚ùå Requisito 2: Almeno 10 immagini per classe -> NON SODDISFATTO (Minimo trovato: {min_class_count})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    verify_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2a5ddf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
